#!/usr/bin/python

__prog__ = 'ccapps_overlaps'
__author__ = 'Collin Capano <collin.capano@ligo.org>'
__description__ = 'Calculates effectualness for a set of signals given a template bank. Values are stored for the best match.'

import sqlite3
import numpy
import os, sys, shutil, getpass
import time
import random
import operator
from optparse import OptionParser

import lal
import lalsimulation as lalsim

from glue.ligolw import utils
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw.utils import process

from pylal import ligolw_sqlutils as sqlutils

import pycbc
from pycbc import filter
from pycbc import types as pytypes

from pycbc.overlaps import waveform_utils
from pycbc.overlaps import overlap_utils

parser = OptionParser(description = __description__)
parser.add_option('-o', '--output-dir', default = '.', help = 'Directory to save overlap output data.')
parser.add_option("-t", "--tmp-space", action = "store", type = "string", default = None, metavar = "PATH", help = "Location of local disk on which to do work. This is used to enhance performance in a networked environment.")
parser.add_option("-p", "--psd-model", help = "What PSD model to use for overlaps. Options are %s." %(', '.join(overlap_utils.get_psd_models())))
parser.add_option("-A", "--asd-file", help = "Load the PSD from a dat file containing an ASD. If both this and psd-model specified, this will take precedence.")
parser.add_option('-f', '--waveform-f-min', type = 'float', help = "Frequency at which to start the waveform generation (in Hz).")
parser.add_option('-F', '--overlap-f-min', type = 'float', help = "Frequency at which to start the overlap (in Hz). Note: This must be larger than waveform-f-min.")
parser.add_option('-r', '--sample-rate', type = 'int', help = "Required. Sample rate to use (in Hz). Must be a power of 2. If vary-n is turned on and the sample rate used to generate the waveforms and compute overlaps is less than this, the effectulaness time series will be upsampled to this sample rate. If the sample rate used in the overlap calculation is greater than this, that sample rate will be used.")
parser.add_option('-l', '--segment-length', type = 'int', help = "Segment length to use (in s). Must be a power of 2. Required if vary-n not used.")
parser.add_option('-n', '--vary-n', action='store_true', default=False, help='If turned on, the sample rate and segment length used will be set to the smallest possible value between a given template and injection. This speeds up overlap calculations, but may reduce the accuracy of the effectualness measurement.')
parser.add_option('-P', '--precision', metavar="[double|single]", default='double', help="What precision to use. Options are 'double' or 'single'. Default is double.")
parser.add_option('-D', '--dyn-range-exp', type=int, default=None, help="What power to use for the dynamic range factor, which = 2**dyn_range_exp. This is necessary if using single precision. Default is %i." %(int(numpy.log2(pycbc.DYN_RANGE_FAC))))
parser.add_option('-i', '--ifo', help = "What ifo to inject into. If none specified, no response function will be applied to the injections.")
parser.add_option('-U', '--user-tag', help = "User tag to add to all Overlap files.")
parser.add_option('-M', '--use-injection-cache', metavar = '"memory" or "disk"', help = "Speed up calculations by using an injection cache. Options are 'memory' or 'disk'. If 'memory', all injections will be stored in memory. If 'disk', injections will be stored to a temporary h5py archive. If a temp-space is specified, this temporary archive will be placed there; otherwise, it will be created in the current working directory.")
parser.add_option('-a', '--approximant', help = "Approximant to use for the templates.")
parser.add_option("", "--amp-order", type=int, default=0, help="Amplitude order to use for templates. Default is 0.")
parser.add_option("", "--phase-order", type=int, default=7, help="Phase order to use for templates. Default is 7 (3.5PN).")
parser.add_option("", "--spin-order", type=int, default=None, help="Spin order to use for templates.")
parser.add_option("", "--taper", help = "For TD approximants, set whether or not to taper the templates at the start and/or end. Options are: start, end, start_end. If not specified, no tapering will be done.")
parser.add_option('', '--match-window-db', help = 'Use the match windows specified in the given database to reduce the number of overlaps computed.')
parser.add_option('', '--save-all-overlaps', action = 'store_true', default = False, help = 'Do not delete the all_overlaps table from the output database before exiting. This table contains the fitting factors for all the injections and templates that were filtered.')
parser.add_option('-R', '--replace', action = 'store_true', default = False, help = 'If the output database already exists, overwrite it. Default action is not to overwrite, in which case only injections that do not have overlap values calculated in the database will be analyzed.')
parser.add_option('-T', '--checkpoint-dt', type = 'float', default = numpy.inf, help = 'Number of minutes between checkpoints. Default is infinity, meaning no checkpointing.')
parser.add_option('-v', '--verbose', action = 'store_true', help = 'Be verbose.')

opts, filenames = parser.parse_args()

# check options
ifo = opts.ifo
if opts.ifo is not None:
    ifo = ifo.upper()
    if len(ifo) != 2:
        raise ValueError("--ifo must be of format [site][number], e.g., 'H1'")
wfmin = opts.waveform_f_min
ofmin = opts.overlap_f_min
if ofmin < wfmin:
    raise ValueError("--waveform-f-min must be less than overlap-f-min")

if opts.sample_rate is None:
    raise ValueError("must specify a sample-rate")
target_sample_rate = opts.sample_rate
if numpy.log2(target_sample_rate) % 1 != 0.:
    raise ValueError("--sample-rate must be a power of 2")

if not opts.vary_n:
    sample_rate = target_sample_rate
    if sample_rate is None or numpy.log2(sample_rate) % 1 != 0.:
        raise ValueError("--sample-rate must be a power of 2")
    if opts.segment_length is None:
        raise ValueError("if not --vary-n, must specify a segment-length")
    seg_length = opts.segment_length
    if seg_length is None or numpy.log2(seg_length) % 1 != 0.:
        raise ValueError("--segment-length must be a power of 2")

if opts.asd_file is None and opts.psd_model is None:
    raise ValueError("must specify --asd-file or --psd-model")
if opts.asd_file is not None and not os.path.exists(opts.asd_file):
    raise ValueError("asd-file %s not found" % opts.asd_file)
if (opts.use_injection_cache is not None and not 
        (opts.use_injection_cache == 'disk' or
        opts.use_injection_cache == 'memory')):
    raise ValueError('if using injection cache, --use-injection-cache must ' +\
        'be set to "disk" or "memory"')
taper = waveform_utils.get_taper_string(opts.taper)

if opts.dyn_range_exp is None:
    dyn_range_fac = pycbc.DYN_RANGE_FAC
else:
    dyn_range_fac = 2.**opts.dyn_range_exp
if opts.precision.lower() == 'single':
    real_type = pytypes.float32
    cmplx_type = pytypes.complex64
elif opts.precision.lower() == 'double':
    real_type = pytypes.float64
    cmplx_type = pytypes.complex128
else:
    raise ValueError, "unrecognized precision %s" %(opts.precision)

# load the param window list
param_windows = {}
if opts.match_window_db is not None:
    connection = sqlite3.connect(opts.match_window_db)
    sqlquery = '''
        SELECT DISTINCT
            inj_apprx
        FROM
            match_windows
        WHERE
            tmplt_apprx == ?
        '''
    apprxs = [apprx[0] for apprx in connection.cursor().execute(sqlquery,
        (opts.approximant,))]
    for apprx in apprxs:
        pwList = overlap_utils.ParamWindowList()
        pwList.load_from_database(connection, 'mchirp', apprx,
            tmplt_apprx=opts.approximant)
        param_windows[apprx] = pwList

# initialize the workspace
workSpace = overlap_utils.WorkSpace()

# set the start time
last_time = time.time()
last_timestamp = 0
last_keylen = 0
last_subkeylen = 0

# set a temp path for backup files
tmp_path = opts.tmp_space is not None and opts.tmp_space or '.'

# get the psd model to use
if opts.asd_file is None:
    psd_model = opts.psd_model

for fnum, infile in enumerate(filenames):

    if opts.verbose:
        print >> sys.stdout, "Analyzing file %s" % infile
    if not os.path.exists(infile):
        raise ValueError, "the input file %s could not be found" % infile
    # get output name
    outfile = overlap_utils.get_outfilename(opts.output_dir, opts.ifo,
        opts.user_tag, fnum)
    if outfile == infile:
        raise ValueError("output file (%s) is the same as the input file " +\
            "(%s)" %(outfile, infile))

    if opts.tmp_space:
        if os.path.exists(outfile) and not opts.replace:
            working_filename = dbtables.get_connection_filename(outfile,
                tmp_path=opts.tmp_space, verbose=opts.verbose)
        else:
            working_filename = dbtables.get_connection_filename(infile,
                tmp_path=opts.tmp_space, verbose=opts.verbose)
        connection = sqlite3.connect(working_filename)
        dbtables.set_temp_store_directory(connection, opts.tmp_space,
            verbose=opts.verbose)
    else:
        if not os.path.exists(outfile) or opts.replace:
            connection = overlap_utils.get_outfile_connection(infile, outfile,
                replace=opts.replace, verbose=opts.verbose)
        else:
            connection = sqlite3.connect(outfile)
        working_filename = None
    # FIXME: dbtables apparently has a problem with overlap_results table
    try:
        xmldoc = dbtables.get_xml(connection)
        this_process = process.register_to_xmldoc(xmldoc, __prog__,
            opts.__dict__).process_id
    except:
        print >> sys.stderr, "Warning: not writing process info to database"
        this_process = sqlutils.get_next_id(connection, 'process',
            'process_id')

    # create the results table in the output if it doesn't exist
    overlap_utils.create_results_table(connection)
    overlap_utils.create_cem_table(connection)
    overlap_utils.create_coinc_definer_table(connection)
    overlap_utils.create_coinc_event_table(connection)
    # create a table to store all of the overlaps;
    # we will delete this when done
    overlap_utils.create_all_results_table(connection)
    
    # create the log table for checkpointing
    overlap_utils.create_log_table(connection)
    # get startup parameters
    startup_dict = overlap_utils.get_startup_data(connection)
    if startup_dict != {}:
        if opts.verbose:
            print >> sys.stdout, "Loaded startup data..."

        # get the backup archive if we're caching to disk
        backup_arxv_fn = startup_dict['backup_archive']
        if backup_arxv_fn is None:
            if opts.use_injection_cache == 'disk':
                archive = waveform_utils.get_scratch_archive(tmp_path,
                    start_archive=backup_arxv_fn)
            else:
                archive = {}
        elif opts.use_injection_cache == 'disk':
            # load the archive
            if backup_arxv_fn.endswith('.hdf5'):
                archive = waveform_utils.get_scratch_archive(tmp_path,
                    start_archive=backup_arxv_fn)
            else:
                # if the last program used a backup archive in memory,
                # we cannot use it; so we just start from scratch
                print >> sys.stderr, "Warning: Backup archive appears to " +\
                    "have been from a dictionary. Will recreate the archive "+\
                    "from scratch as an hdf5 file."
                archive = waveform_utils.get_scratch_archive(tmp_path,
                    start_archive=None)
        elif (opts.use_injection_cache == 'memory' and
                backup_arxv_fn.endswith('.pickle')):
            archive = overlap_utils.load_backup_archive_dict(backup_arxv_fn)
        else:
            archive = {}

        # get the starting index
        start_idx = startup_dict['tmplt_num'] + 1
        start_inj_idx = startup_dict['inj_num'] + 1

    else:
        start_idx = 0
        start_inj_idx = 0
        if opts.use_injection_cache == 'disk':
            archive = waveform_utils.get_scratch_archive(tmp_path,
                start_archive=None)
        else:
            archive = {}

    # get injections that were already analyzed
    sqlquery = """
        SELECT
            map.event_id, results.sample_rate, results.segment_length,
            results.num_tries
        FROM
            overlap_results as results
        JOIN
            coinc_event_map AS map
        ON
            map.coinc_event_id == results.coinc_event_id
        WHERE
            map.table_name == "sim_inspiral"
        """
    already_analyzed = dict([ [sim_id, (sr, sl, nt)] for (sim_id, sr, sl, nt)
        in connection.cursor().execute(sqlquery)])

    # get the templates
    templates = waveform_utils.TemplateDict()
    templates.get_templates(connection, opts.approximant, wfmin,
        amp_order=opts.amp_order, phase_order=opts.phase_order,
        spin_order=opts.spin_order, taper=taper,
        calc_f_final=True, estimate_dur=True, verbose=opts.verbose,
        only_matching=False)
    templates.clear_sigmas()
    if opts.verbose:
        print >> sys.stdout, "Database contains %i templates" %(
            len(templates.keys()))

    # order the templates by sample rate, duration
    templates.set_sort_key(['_f_final', '_duration'])

    # check that the tmplt_id matches
    if startup_dict and startup_dict['tmplt_id'] is not None:
        check_tid = templates.as_list[start_idx-1].tmplt_id
        if startup_dict['tmplt_id'] != check_tid:
            raise ValueError("starting tmplt_id-1 (%s) " %(check_tid) +\
                "does not match last tmplt_id in log table (%s)" %(
                startup_dict['tmplt_id']))
        elif opts.verbose:
            print >> sys.stdout, "Starting with template %i..." % (start_idx)

    # get the injections
    injections = waveform_utils.InjectionDict()
    injections.get_injections(connection, wfmin, archive=archive,
        calc_f_final=opts.vary_n, estimate_dur=opts.vary_n,
        verbose=opts.verbose)
    injections.clear_sigmas()
    # if vary n, set sort key
    if opts.vary_n:
        injections.set_sort_key(['_f_final', '_duration'])

    # check that the simulation_id matches
    if startup_dict and startup_dict['simulation_id'] is not None:
        check_id = str(injections.as_list[start_inj_idx - 1].simulation_id)
        if startup_dict['simulation_id'] != check_id:
            raise ValueError("starting simulation_id (%s) " %(check_id) +\
                "does not match last simulation_id in log table (%s)" %(
                startup_dict['simulation_id']))
        elif opts.verbose:
            print >> sys.stdout, "Starting with injection %i..." % (
                start_inj_idx)

    #
    #   Find the best match via fitting factor
    #
    if opts.verbose:
        verb_string = "Template %s%s: Injection %s%s\r"
        wpad1 = ''.join([' ' for vv in range(len(str(len(templates))))])
        wpad2 = ''.join([' ' for vv in range(len(str(len(injections))))])
   
    # we will keep track of the the previous sample rates and durations
    # used as we cycle over the injections and templates to minimize
    # the number of times we generate the waveforms
    last_tmplt_rate = 0
    # inj rate is a dictionary keyed by simulation_ids so as not to
    # regenerate the injection every time we regenerate the template
    last_inj_rate = {}
    # ditto for durations
    last_tmplt_N = 0
    last_inj_N = {}

    # cycle over the templates
    for jj in range(start_idx, len(templates.as_list)):

        tmplt = templates.as_list[jj]
        h = htilde = None

        # cycle over the injections 
        for ii, inj in enumerate(injections.as_list):
            # skip if already done at start
            if jj == start_idx and ii < start_inj_idx:
                continue

            if opts.verbose:
                lbl1 = str(jj+1)
                lbl2 = str(ii+1)
                print >> sys.stdout, verb_string %(wpad1[:-len(lbl1)], lbl1,
                    wpad2[:-len(lbl2)], lbl2),
                sys.stdout.flush()

            # check if the template falls within this injection's param window
            try:
                pwList = param_windows[inj.approximant]
                pwin = pwList[pwList.find(inj.mchirp)]
                if tmplt.mchirp not in pwin.recovery_window(inj.mchirp):
                    continue
            except KeyError:
                pass

            # get the sample rate and segment length to use
            if opts.vary_n:
                sample_rate = int(2**(numpy.ceil(numpy.log2(
                    max(tmplt.get_f_final(), inj.get_f_final()))+1)))

                # get the segment length to use
                # we'll set the segment length to be twice the max duration
                # of this template and the injection
                seg_length = int(2**(numpy.ceil(numpy.log2(
                    max(tmplt.get_duration(), inj.get_duration())))+1))

                # since the duration estimates are based on the 2PN
                # approximation, the duration may be too short; we'll just put
                # a floor at 2s
                if seg_length < 2:
                    seg_length = 2

                # for TD waveforms, if the sample rate isn't the same as the
                # last, have to regenerate the template
                if lalsim.SimInspiralImplementedTDApproximants(
                        lalsim.GetApproximantFromString(tmplt.approximant)) \
                        and (sample_rate != last_tmplt_rate or not h):
                    h = tmplt.get_td_waveform(sample_rate,
                            seg_length, store=False)

            N = seg_length * sample_rate
            df = 1./seg_length

            # if the duration isn't the same as the last used, have to
            # regenerate the FD form of the template, and get the correct
            # sized workspace vectors (note that this will only get
            # triggered once if not varying n)
            if N != last_tmplt_N or sample_rate != last_tmplt_rate or \
                    not htilde:
                # get the psd and needed workspace vectors
                if opts.asd_file is not None:
                    psd = workSpace.get_psd_from_file(df, wfmin, sample_rate,
                        opts.asd_file, dyn_range_fac=dyn_range_fac)
                else:
                    psd = workSpace.get_psd(df, wfmin, sample_rate, psd_model,
                        dyn_range_fac=dyn_range_fac)
                
                psd = psd.astype(real_type)

                if opts.vary_n and lalsim.SimInspiralImplementedTDApproximants(
                        lalsim.GetApproximantFromString(tmplt.approximant)):
                    htilde = filter.make_frequency_series(h)
                else:
                    htilde = tmplt.get_fd_waveform(sample_rate, seg_length,
                        store=False)
                htilde = htilde * dyn_range_fac
                htilde = htilde.astype(cmplx_type)

            last_tmplt_rate = sample_rate
            last_tmplt_N = N
           
            # set the segment start time; we'll always make this to be
            # the injection's end_time - 1.5 times its estimated duration
            segment_start = inj.detector_end_time(ifo) - 1.5*inj.get_duration()

            # for the injection, we just need to update the archive
            # appropriately: if the TD or FD waveform doesn't exist at the
            # desired rate/length in the archive, the code in waveform_utils
            # will update it automatically
            last_rate = last_inj_rate.setdefault(
                str(inj.simulation_id), 0)
            last_N = last_inj_N.setdefault(str(inj.simulation_id), 0)
            if sample_rate != last_rate:
                # means we have to regenerate both the TD and FD waveform, so
                # we clear the archive of the injection's instances of both at
                # the prior rate/duration
                inj.del_from_archive(sample_rate, seg_length, ifo,
                    segment_start, 'TD')
                inj.del_from_archive(sample_rate, seg_length, ifo,
                    segment_start, 'FD')
            if N != last_N:
                # means we have to delete the FD waveform
                inj.del_from_archive(sample_rate, seg_length, ifo,
                    segment_start, 'FD')

            # as a last cleanup, delete any dangling keys that no longer point
            # to anything in the archive
            for key in archive.keys():
                if archive[key].values() == []:
                    del archive[key]

            # update the rate/duration dicts
            last_inj_rate[str(inj.simulation_id)] = sample_rate
            last_inj_N[str(inj.simulation_id)] = N

            # get the FD injection; this will also store the TD injection if it
            # doesn't exist in the archive
            htildeprime = inj.get_fd_waveform(sample_rate, seg_length,
                ifo, segment_start, store=opts.use_injection_cache is not None)

            htildeprime = htildeprime * dyn_range_fac
            htildeprime = htildeprime.astype(cmplx_type)
            
            # get the normalization of htilde, htildeprime if they aren't known yet
            if inj.sigma is None:
                inj.sigma = filter.sigma(htildeprime, psd, ofmin)
            if tmplt.sigma is None:
                tmplt.sigma = filter.sigma(htilde, psd, ofmin)

            # get work vectors
            out_work_mem = workSpace.get_out_vec(N,
                pytypes.complex_same_precision_as(htilde))
            corr_work_mem = workSpace.get_corr_vec(N,
                pytypes.complex_same_precision_as(htilde))

            # compute effectualness
            # Note that because we padded the segment length to be twice the
            # length of htildeprime and htilde, we do not need to worry
            # about corruption
            cmplx_ts, _, norm, maxidx, offset, _ = overlap_utils.filter_by_resampling(
                htilde, htildeprime, psd, ofmin, target_sample_rate,
                max_resample_length=2, h_norm=tmplt.sigma**2, out=out_work_mem,
                corr_out=corr_work_mem)

            effectualness = abs(cmplx_ts[maxidx]*norm)/inj.sigma

            time_offset = segment_start + maxidx*cmplx_ts.delta_t + offset - \
                inj.geocent_time

            # store
            thisResult = overlap_utils.OverlapResult(tmplt, inj)
            thisResult.segment_length = seg_length
            thisResult.sample_rate = sample_rate
            thisResult.overlap_f_min = ofmin 
            thisResult.waveform_f_min = wfmin
            thisResult.tmplt_approximant = opts.approximant 
            thisResult.effectualness = effectualness
            thisResult.time_offset = time_offset.gpsSeconds
            thisResult.time_offset_ns = time_offset.gpsNanoSeconds
            thisResult.write_all_results_to_database(connection)

            # check time and update checkpoints if needed
            now = time.time()
            if (now - last_time)/60. > opts.checkpoint_dt:
                if opts.verbose:
                    print >> sys.stdout, "\ncheckpointing..."
                    sys.stdout.flush()
                # FIXME: never backing up archive
                archive = overlap_utils.checkpoint(connection, opts.output_dir,
                    archive, now, str(inj.simulation_id), ii,
                    str(tmplt.tmplt_id), jj, getpass.getuser(),
                    backup_archive=False)
                if working_filename is not None:
                    # to avoid copy errors, we need to move the database over
                    # then move it back
                    dbtables.put_connection_filename(outfile, working_filename,
                        verbose=False)
                    working_filename = dbtables.get_connection_filename(
                        outfile, tmp_path=opts.tmp_space, verbose=False)
                    connection = sqlite3.connect(working_filename)
                    dbtables.set_temp_store_directory(connection,
                        opts.tmp_space, verbose = False)
                last_time = now

    #
    #   Best Match Calculations
    #
    # done cycling over templates, find the best match for each injection
    if opts.verbose:
        print >> sys.stdout, "\nFinding best match and calculating " +\
            "expectation values:"

    # get the points that have already been written to overlap_results
    # XXX: start here
    best_match_query = """
        SELECT
            a.simulation_id, a.tmplt_id, a.effectualness, a.time_offset,
            a.time_offset_ns, a.segment_length, a.sample_rate
        FROM
            all_results AS a
        WHERE
            a.simulation_id == ?
        ORDER BY
            effectualness
        DESC LIMIT 1"""

    for ii, inj in enumerate(injections.as_list):

        if opts.verbose:
            print >> sys.stdout, "Injection %i          \r" % ii,
            sys.stdout.flush()
    

        # get the best match for this injection
        simid, tmpltid, eff, dt, dt_ns, seg_length, sample_rate = \
            connection.cursor().execute(best_match_query,
            (str(inj.simulation_id),)).fetchone()

        bestMatch = overlap_utils.OverlapResult(templates[tmpltid],
            injections[simid])
        bestMatch.effectualness = eff
        bestMatch.time_offset = dt
        bestMatch.time_offset_ns = dt_ns
        bestMatch.segment_length = seg_length
        bestMatch.sample_rate = sample_rate
        bestMatch.overlap_f_min = ofmin 
        bestMatch.waveform_f_min = wfmin
        bestMatch.tmplt_approximant = opts.approximant 
      
        overlap_utils.write_result_to_database(connection, bestMatch,
            'no_weight', this_process)

        # check time and update checkpoints if needed
        now = time.time()
        if (now - last_time)/60. > opts.checkpoint_dt:
            if opts.verbose:
                print >> sys.stdout, "\ncheckpointing..."
                sys.stdout.flush()
            archive = overlap_utils.checkpoint(connection, opts.output_dir,
                archive, now, str(injections.as_list[-1].simulation_id),
                len(injections.as_list)-1, str(templates.as_list[-1].tmplt_id),
                len(templates.as_list)-1, getpass.getuser(),
                backup_archive=False)
            if working_filename is not None:
                # to avoid copy errors, we need to move the database over
                # then move it back
                dbtables.put_connection_filename(outfile, working_filename,
                    verbose=False)
                working_filename = dbtables.get_connection_filename(outfile,
                    tmp_path = opts.tmp_space, verbose=False)
                connection = sqlite3.connect(working_filename)
                dbtables.set_temp_store_directory(connection, opts.tmp_space,
                    verbose=False)
            last_time = now

    if opts.verbose:
        print >> sys.stdout, ""
        sys.stdout.flush()
    
    # move onto next file
    if opts.use_injection_cache == 'disk':
        waveform_utils.close_scratch_archive(archive)
    # move the working database to the outfile and delete backups
    overlap_utils.clean_backup_files(connection)
    connection.commit()
    if not opts.save_all_overlaps:
        if opts.verbose:
            print >> sys.stdout, "Dropping all_results table and vacuuming..."
        connection.cursor().execute('DROP TABLE all_results')
        connection.commit()
        connection.cursor().execute('VACUUM')
        connection.commit()
    connection.close()
    if opts.tmp_space is not None:
        dbtables.put_connection_filename(outfile, working_filename,
            verbose=opts.verbose)

if opts.verbose:
    print >> sys.stdout, "Finished!"

sys.exit(0)
