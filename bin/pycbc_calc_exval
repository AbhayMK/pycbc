#! /usr/bin/env python

__prog__ = 'pycbc_calc_exval'
__author__ = 'Collin Capano <collin.capano@ligo.org>'
__description__ = \
"""Calculates SNR, and chisq values for a set of signals given a set of
injections with matching templates. Values are stored for the best match,
determined by SNR and New SNR."""

import sqlite3
import numpy
import os, sys, shutil
import time
import random
import pickle
import operator
from optparse import OptionParser

import lal
import lalsimulation as lalsim

from glue.ligolw import utils
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw.utils import process

from pylal import ligolw_sqlutils as sqlutils

from pycbc import types as pytypes
from pycbc.types import complex_same_precision_as
from pycbc import filter
from pycbc import noise
from pycbc import vetoes
from pycbc.overlaps import waveform_utils, overlap_utils

parser = OptionParser(description = __description__)
parser.add_option('-o', '--output-dir', default = '.', help = 'Directory to save overlap output data. Default is current.')
parser.add_option("-t", "--tmp-space", action = "store", type = "string", default = None, metavar = "PATH", help = "Location of local disk on which to do work. This is used to enhance performance in a networked environment.")
parser.add_option("-p", "--psd-model", help = "What PSD model to use for overlaps. Options are %s." %(', '.join(overlap_utils.get_psd_models())))
parser.add_option("-A", "--asd-file", help = "Load the PSD from a dat file containing an ASD. If both this and psd-model specified, this will take precedence.")
parser.add_option('-f', '--waveform-f-min', type = 'float', help = "Frequency at which to start the waveform generation (in Hz).")
parser.add_option('-F', '--overlap-f-min', type = 'float', help = "Frequency at which to start the overlap (in Hz). Note: This must be larger than waveform-f-min.")
parser.add_option('-n', '--n-realizations', type = 'int', help = "Number of noise realizations to generate to calculate the mean snr, chisq, and new-snr.")
parser.add_option('-i', '--ifo', help = "What ifo to inject into.")
parser.add_option('--no-response-func', action = 'store_true', default = False, help = "Do not apply the detector response function to the injections. This will effectively put all injections overhead the detector. The injections' inclination angles will still be applied, however.")
parser.add_option('-U', '--user-tag', help = "User tag to add to all Overlap files.")
parser.add_option('-a', '--approximant', help = "Approximant to use for the templates.")
parser.add_option('-b', '--n-chisq-bins', type = 'int', help = 'Number of chisq bins to use.')
parser.add_option('-T', '--checkpoint-dt', type = 'float', default = numpy.inf, help = 'Number of minutes between checkpoints. Default is infinity, meaning no checkpointing.')
parser.add_option('-R', '--replace', action='store_true', default=False, help = 'If the output database already exists, overwrite it. Default action is not to overwrite.')
parser.add_option('-X', '--overwrite-results', action = 'store_true', default = False, help = 'If snr, chisq, and new snr already exist in the database, overwrite them. Otherwise, results with these values populated will be skipped. Note that this turning this option on effectively turns off checkpointing.')
parser.add_option('-S', '--seed', type = 'int', default = int((time.time()*100)% 1e6), help = 'Set the seed to use for the gaussian noise generator. If none specified, will use the current time.')
parser.add_option('-v', '--verbose', action = 'store_true', help = 'Be verbose.')

opts, filenames = parser.parse_args()

# check options
if opts.ifo is None:
    raise ValueError, "--ifo required"
ifo = opts.ifo.upper()
if len(ifo) != 2:
    raise ValueError, "--ifo must be of format [site][number], e.g., 'H1'"
if ifo.startswith('T'):
    raise ValueError, "Because eff_dist_t is used to store target snrs, --ifo cannot start with T"
wfmin = opts.waveform_f_min
ofmin = opts.overlap_f_min
if ofmin < wfmin:
    raise ValueError, "--waveform-f-min must be less than overlap-f-min"
if not opts.n_realizations:
    raise ValueError, "--n-realizations required"
if opts.asd_file is None and opts.psd_model is None:
    raise ValueError, "must specify --asd-file or --psd-model"
if opts.asd_file is not None and not os.path.exists(opts.asd_file):
    raise ValueError, "asd-file %s not found" % opts.asd_file

# set the start time
last_time = time.time()

# initialize the workspace
work_space = overlap_utils.WorkSpace()

# get the psd model to use
if opts.asd_file is None:
    psd_model = opts.psd_model
    min_length = 0
# if using an asd file, the df must be greater than what's in the file
else:
    min_length = 1. / overlap_utils.get_asd_file_df(opts.asd_file)

for fnum, infile in enumerate(filenames):

    if opts.verbose:
        print >> sys.stdout, "Analyzing file %s" % infile
    if not os.path.exists(infile):
        raise ValueError, "the input file %s could not be found" % infile

    outfile = overlap_utils.get_exval_outfilename(opts.output_dir, opts.ifo,
        opts.user_tag, fnum)
    if outfile == infile:
        raise ValueError, "output file (%s) is the same " % outfile +\
            "as the input file (%s)" %(infile)

    if opts.tmp_space:
        if os.path.exists(outfile) and not opts.replace:
            working_filename = dbtables.get_connection_filename(outfile,
                tmp_path = opts.tmp_space, verbose = opts.verbose)
        else:
            working_filename = dbtables.get_connection_filename(infile,
                tmp_path = opts.tmp_space, verbose = opts.verbose)
        connection = sqlite3.connect(working_filename)
        dbtables.set_temp_store_directory(connection, opts.tmp_space,
            verbose=opts.verbose)
    else:
        connection = overlap_utils.get_outfile_connection(infile, outfile,
            replace=opts.replace, verbose=opts.verbose)

    # FIXME: dbtables apparently has a problem with overlap_results table
    try:
        xmldoc = dbtables.get_xml(connection)
        this_process = process.register_to_xmldoc(xmldoc, __prog__,
            opts.__dict__).process_id
    except:
        print >> sys.stderr, "Warning: not writing process info to database"
        this_process = sqlutils.get_next_id(connection, 'process',
            'process_id')

    # get the injections and matching templates
    results, injections, templates = overlap_utils.get_matching_results(
        connection, opts.approximant, wfmin, verbose = opts.verbose)

    # get results that have already been analyzed
    sqlquery = """
        SELECT
            overlap_results.coinc_event_id
        FROM
            overlap_results
        WHERE
            snr IS NOT NULL AND
            chisq IS NOT NULL AND
            new_snr IS NOT NULL
        """
    if opts.overwrite_results:
        already_analyzed = []
    else:
        already_analyzed = [ceid for (ceid,) in
            connection.cursor().execute(sqlquery)]

    #
    #   Cycle over the results, calculating the expectation values for each
    #
    for ii, (ceid, this_result) in enumerate(results.items()):

        if ceid in already_analyzed:
            continue

        if opts.verbose:
            print >> sys.stdout, "Injection %i\r" % (ii+1),
            sys.stdout.flush()
        
        # get the filtering parameters to use
        sample_rate = this_result.sample_rate
        ofmin = this_result.overlap_f_min
        wfmin = this_result.waveform_f_min

        # get the time-domain injection and template
        tmplt = templates[this_result.event_id]
        h = tmplt.get_waveform(sample_rate, taper='start', store=False)

        inj = injections[this_result.simulation_id]
        hprime = inj.get_waveform(sample_rate, wfmin,
            apply_ifo_response=not opts.no_response_func, ifo=ifo,
            optimally_oriented=False, store=False)

        # calculate the segment length to use
        N = int(2**(numpy.ceil(numpy.log2(max(len(h), len(hprime),
            sample_rate*min_length)))+2))
        seg_length = N / sample_rate
        df = 1./seg_length

        snr_work_mem = pytypes.zeros(N,
            dtype=complex_same_precision_as(hprime))
        corr_work_mem = pytypes.zeros(N,
            dtype=complex_same_precision_as(hprime))

        # get psd and needed workspace vectors
        if opts.asd_file is not None:
            psd = work_space.get_psd_from_file(df, wfmin, sample_rate,
                opts.asd_file)
        else:
            psd = work_space.get_psd(df, wfmin, sample_rate, psd_model)

        # zero-pad the template and transform
        h = waveform_utils.position_td_template(h, N)
        htilde = waveform_utils.get_htilde(h)


        # we put the injection in the middle of the segment
        hprime = waveform_utils.zero_pad_h(hprime, N, N/2)
        htildeprime = waveform_utils.get_htilde(hprime)

        # cycle over the desired number of sample times, calculating snr,
        # chisq, and newsnr for each
        snrs = []
        chisq_vals = []
        newsnrs = []
        num_successes = 0
        for nn in range(opts.n_realizations):
            # create an instance of the noise
            # pycbc's noise package will give the same noise if you pass the
            # seed argument everytime. We therefore only pass it a seed on
            # the first pass.
            if nn == 0:
                seed = opts.seed
            else:
                seed = None
            ntilde = noise.frequency_noise_from_psd(psd, seed=seed)

            # add the injection
            stilde = ntilde + htildeprime
        
            # compute snr
            cmplx_snr, corr, norm = filter.matched_filter_core(htilde, stilde,
                psd=psd, h_norm=None, low_frequency_cutoff=ofmin,
                out=snr_work_mem, corr_out=corr_work_mem)
            maxidx = abs(cmplx_snr.data[N/4:3*N/4]).argmax() + N/4
            snr = abs(cmplx_snr.data[maxidx]*norm)

            snr2 = abs(filter.matched_filter(htilde, stilde, psd,
                ofmin).data[N/4:3*N/4]).max()
            # check what the loudest event in noise is
            randsnr = abs(filter.matched_filter(htilde, ntilde, psd,
                ofmin).data[N/4:3*N/4]).max()
           
            # only calculate chisq if the snr is louder than noise
            if snr > randsnr:

                # get the chisq bins
                bins = vetoes.power_chisq_bins(htilde, opts.n_chisq_bins, psd,
                    ofmin)

                #chisq = vetoes.power_chisq_at_points_from_precomputed(corr,
                #   numpy.array([snr*norm]), norm, bins,
                #   numpy.array([maxidx]))[0]
                chisqts = vetoes.chisq.power_chisq_from_precomputed(corr,
                    cmplx_snr, norm, bins)
                chisq = chisqts[maxidx]
                
                newsnr = overlap_utils.new_snr(snr, chisq,
                    2*opts.n_chisq_bins - 2)

                snrs.append(snr)
                chisq_vals.append(chisq)
                newsnrs.append(newsnr)
                num_successes += 1

        # compute mean, st. devs.
        if num_successes > 0:
            snrs = numpy.array(snrs)
            chisq_vals = numpy.array(chisq_vals)
            newsnrs = numpy.array(newsnrs)
            this_result.snr = snrs.mean()
            this_result.snr_std = snrs.std()
            this_result.chisq = chisq_vals.mean()
            this_result.chisq_std = chisq_vals.std()
            this_result.chisq_dof = 2*opts.n_chisq_bins - 2
            this_result.new_snr = newsnrs.mean()
            this_result.new_snr_std = newsnrs.std()
        else:
            this_result.snr = 0
            this_result.snr_std = 0
            this_result.chisq = 0
            this_result.chisq_std = 0
            this_result.chisq_dof = 0
            this_result.new_snr = 0
            this_result.new_snr_std = 0

        this_result.num_tries = opts.n_realizations
        this_result.num_successes = num_successes

        # dump to output database
        sqlquery = """
            UPDATE
                overlap_results
            SET
                snr = ?, snr_std = ?, chisq = ?, chisq_std = ?, chisq_dof = ?,
                new_snr = ?, new_snr_std = ?
            WHERE
                coinc_event_id = ?"""
        connection.cursor().execute(sqlquery, (this_result.snr,
            this_result.snr_std, this_result.chisq, this_result.chisq_std,
            this_result.chisq_dof, this_result.new_snr,
            this_result.new_snr_std, ceid))
        connection.commit()

        # check time and update checkpoints if needed
        now = time.time()
        if (now - last_time)/60. > opts.checkpoint_dt and \
                opts.tmp_space is not None:
            if opts.verbose:
                print "\ncheckpointing..."
            overlap_utils.copy_to_output(working_filename,
                outfile, verbose=False)
            last_time = now

    if opts.verbose:
        print >> sys.stdout, ""
        sys.stdout.flush()
    
    # close and exit 
    connection.commit()
    connection.close()
    if opts.tmp_space is not None:
        dbtables.put_connection_filename(outfile, working_filename,
            verbose=opts.verbose)

if opts.verbose:
    print >> sys.stdout, "Finished!"

sys.exit(0)
