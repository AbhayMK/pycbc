#!/usr/bin/python
""" This program adds single detector hdf trigger files together.
"""
import numpy, argparse, h5py, logging

parser = argparse.ArgumentParser()
parser.add_argument('--trigger-files', nargs='+')
parser.add_argument('--output-file')
parser.add_argument('--bank-file')
parser.add_argument('--verbose', '-v', action='count')
args = parser.parse_args()

logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO) 

f = h5py.File(args.output_file, 'w')

def hash_lookup(bank_file):
    return h5py.File(bank_file, 'r')['template_hash'][:]

logging.info("getting the list of columns from a representative file")
empty = True
trigger_columns = []
ifo = None
for fname in args.trigger_files:
    f2 = h5py.File(fname, 'r')
    ifo = f2.keys()[0]
    if len(f2[ifo].keys()) > 0:
        k = f2[ifo].keys()
        k.remove('search')
        trigger_columns = f2[ifo][k[0]].keys()
        f2.close()
        break
    f2.close()

logging.info('reading the metadata from the files')
start = numpy.array([], dtype=numpy.float64)
end = numpy.array([], dtype=numpy.float64)
for filename in args.trigger_files:
    data = h5py.File(filename, 'r')
    s, e = data['%s/search/start_time' % ifo][:], data['%s/search/end_time' % ifo][:]
    start, end = numpy.append(start, s), numpy.append(end, e)
    data.close()    
f['%s/search/start_time' % ifo], f['%s/search/end_time' % ifo] = start, end   


logging.info('reading the trigger columns from the input files')
hashes = hash_lookup(args.bank_file)

for i, h in enumerate(hashes):
    for col in trigger_columns:
        data = []
        for fname in args.trigger_files:
            fin = h5py.File(fname)
            if '%s/%s' % (ifo, h) in fin:
                data += [fin['%s/%s/%s' % (ifo, h, col)][:]]
            fin.close()
        f.create_dataset('%s/%s/%s' % (ifo, i, col), 
                 data=numpy.concatenate(data), compression='gzip', shuffle=True) 
logging.info('done')
